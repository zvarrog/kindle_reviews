"""
–ú–æ–¥—É–ª—å –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π.
"""

from pathlib import Path
from typing import Tuple, Dict, List
import pandas as pd
from .feature_space import NUMERIC_COLS
from scripts.data_validation import validate_parquet_dataset, log_validation_results
from scripts.settings import PROCESSED_DATA_DIR, SEED
import logging

log = logging.getLogger("data_loading")


def load_splits() -> (
    Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.Series, pd.Series, pd.Series]
):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–ª–∏—Ç—ã; –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç val/test ‚Äî —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ.
    """
    from sklearn.model_selection import train_test_split

    base = Path(PROCESSED_DATA_DIR)

    # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Å–µ—Ö parquet —Ñ–∞–π–ª–æ–≤
    log.info("üîç –ó–∞–ø—É—Å–∫ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ parquet –¥–∞–Ω–Ω—ã—Ö...")
    validation_results = validate_parquet_dataset(base)
    all_valid = log_validation_results(validation_results)

    if not all_valid:
        log.warning("‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –¥–∞–Ω–Ω—ã–º–∏, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ...")
    else:
        log.info("‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")

    train_p = base / "train.parquet"
    val_p = base / "val.parquet"
    test_p = base / "test.parquet"
    if not train_p.exists():
        raise FileNotFoundError(f"–ù–µ—Ç train.parquet: {train_p}")
    df_train = pd.read_parquet(train_p)
    if not {"reviewText", "overall"}.issubset(df_train.columns):
        raise KeyError("–û–∂–∏–¥–∞—é—Ç—Å—è –∫–æ–ª–æ–Ω–∫–∏ 'reviewText' –∏ 'overall'")

    frames = {"train": df_train}
    if val_p.exists():
        frames["val"] = pd.read_parquet(val_p)
    if test_p.exists():
        frames["test"] = pd.read_parquet(test_p)

    if "val" not in frames or "test" not in frames:
        full = df_train.copy()
        if "val" in frames:
            full = pd.concat([full, frames["val"]], ignore_index=True)
        if "test" in frames:
            full = pd.concat([full, frames["test"]], ignore_index=True)
        full = full.dropna(subset=["reviewText", "overall"])
        y_full = full["overall"].astype(int)
        temp_X, X_test, temp_y, y_test = train_test_split(
            full, y_full, test_size=0.15, stratify=y_full, random_state=SEED
        )
        X_train, X_val, y_train, y_val = train_test_split(
            temp_X, temp_y, test_size=0.17647, stratify=temp_y, random_state=SEED
        )
    else:
        X_train = frames["train"]
        X_val = frames["val"]
        X_test = frames["test"]
        y_train = X_train["overall"].astype(int)
        y_val = X_val["overall"].astype(int)
        y_test = X_test["overall"].astype(int)

    def clean(df: pd.DataFrame):
        keep = ["reviewText", "overall"] + [c for c in NUMERIC_COLS if c in df.columns]
        return df[keep].dropna(subset=["reviewText", "overall"])

    X_train = clean(X_train)
    X_val = clean(X_val)
    X_test = clean(X_test)
    y_train = X_train["overall"].astype(int)
    y_val = X_val["overall"].astype(int)
    y_test = X_test["overall"].astype(int)

    return X_train, X_val, X_test, y_train, y_val, y_test
