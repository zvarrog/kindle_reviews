services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: admin
      POSTGRES_DB: optuna
    ports:
      - '5432:5432'
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U admin -d optuna']
      interval: 5s
      timeout: 5s
      retries: 10

  airflow:
    build:
      context: .
      dockerfile: docker/airflow/dockerfile
    # Используем отдельную БД airflow_meta для метаданных Airflow, чтобы не конфликтовать с Optuna
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__LOAD_EXAMPLES: 'False'
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: 'postgresql+psycopg2://admin:admin@postgres:5432/airflow_meta'
      OPTUNA_STORAGE: 'postgresql+psycopg2://admin:admin@postgres:5432/optuna'
      JAVA_HOME: /usr/lib/jvm/default-java
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./data/raw:/opt/airflow/data/raw
      - ./data/processed:/opt/airflow/data/processed
      - ./scripts:/opt/airflow/scripts
      - ./tests:/opt/airflow/tests
      - ./model:/opt/airflow/model
      - ./mlruns:/opt/airflow/mlruns
      - ${USERPROFILE}/.kaggle/kaggle.json:/home/airflow/.kaggle/kaggle.json:ro
    ports:
      - '8080:8080'
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
    command:
      - bash
      - -c
      - |
        set -e
        airflow db migrate
        airflow users list | grep -q admin@example.com || airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
        airflow webserver -p 8080 &
        airflow scheduler

  downloader:
    build:
      context: .
      dockerfile: docker/downloader/dockerfile
    image: downloader
    volumes:
      - ${USERPROFILE}/.kaggle/kaggle.json:/root/.kaggle/kaggle.json:ro
      - ./scripts/config.py:/app/scripts/config.py
      - ./scripts/download.py:/app/scripts/download.py
      - ./data/raw:/app/data/raw

  spark_processor:
    build:
      context: .
      dockerfile: docker/spark_processor/dockerfile
    image: spark_processor
    volumes:
      - ./data/raw:/app/data/raw
      - ./data/processed:/app/data/processed
      - ./scripts/config.py:/app/scripts/config.py
    environment:
      PYTHONUNBUFFERED: '1'

  api:
    build:
      context: .
      dockerfile: docker/api/dockerfile
    image: kindle_api
    depends_on:
      - spark_processor
    ports:
      - '8000:8000'
    volumes:
      - ./model:/app/model:ro
      - ./scripts/config.py:/app/scripts/config.py:ro

  trainer:
    build:
      context: .
      dockerfile: docker/trainer/dockerfile
    image: kindle_trainer
    volumes:
      - ./data/processed:/app/data/processed
      - ./model:/app/model
      - ./scripts:/app/scripts
      - ./mlruns:/app/mlruns
    environment:
      FORCE_TRAIN: '0'
      OPTUNA_STORAGE: postgresql+psycopg2://admin:admin@postgres:5432/optuna
    depends_on:
      postgres:
        condition: service_healthy
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia

volumes:
  pgdata:
