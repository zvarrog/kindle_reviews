services:
  airflow:
    build:
      context: .
      dockerfile: docker/airflow/dockerfile
    environment:
      - AIRFLOW__CORE__EXECUTOR=SequentialExecutor
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - JAVA_HOME=/usr/lib/jvm/default-java
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./data/raw:/opt/airflow/data/raw
      - ./data/processed:/opt/airflow/data/processed
      - ./scripts:/opt/airflow/scripts
      - ./tests:/opt/airflow/tests
      - ${USERPROFILE}/.kaggle/kaggle.json:/home/airflow/.kaggle/kaggle.json:ro
    ports:
      - '8080:8080'
    command: ['airflow', 'standalone']
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G
  # restart: unless-stopped
  downloader:
    build:
      context: .
      dockerfile: docker/downloader/dockerfile
    image: downloader
    volumes:
      - ${USERPROFILE}/.kaggle/kaggle.json:/root/.kaggle/kaggle.json:ro
      - ./scripts/config.py:/app/scripts/config.py
      - ./scripts/download.py:/app/scripts/download.py
      - ./data/raw:/app/data/raw
  spark_processor:
    build:
      context: .
      dockerfile: docker/spark_processor/dockerfile
    image: spark_processor
    volumes:
      - ./data/raw:/app/data/raw
      - ./data/processed:/app/data/processed
      - ./scripts/config.py:/app/scripts/config.py
    environment:
      - PYTHONUNBUFFERED=1

  api:
    build:
      context: .
      dockerfile: docker/api/dockerfile
    image: kindle_api
    depends_on:
      - spark_processor
    ports:
      - "8000:8000"
    volumes:
      - ./model:/app/model:ro
      - ./scripts/config.py:/app/scripts/config.py:ro
  # Не запрашиваем GPU для API — убираем deploy.resources, чтобы контейнер стартовал
  # (GPU нужен только для trainer; включайте GPU вручную, если система поддерживает nvidia-container-toolkit)

  trainer:
    build:
      context: .
      dockerfile: docker/trainer/dockerfile
    image: kindle_trainer
    volumes:
      - ./data/processed:/app/data/processed
      - ./model:/app/model
      - ./scripts:/app/scripts
      - ./optuna_study.db:/app/optuna_study.db
      - ./mlruns:/app/mlruns
    environment:
      - FORCE_TRAIN=1
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
              driver: nvidia
    # Для Docker Compose v2 (без Swarm):
    # gpus: all
